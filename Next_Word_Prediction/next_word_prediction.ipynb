{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghj3ERVrj8GB"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2iRr3B8lgc9"
      },
      "outputs": [],
      "source": [
        "file = open('data.txt', 'r', encoding='utf-8')\n",
        "lines = []\n",
        "for i in file:\n",
        "    lines.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5UKot1cli0O"
      },
      "outputs": [],
      "source": [
        "dataset = []\n",
        "for i in lines:\n",
        "    dataset = ' '.join(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKJoiwk2llYF"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.replace('\\n','').replace('\\r','').replace('\\ufeff','').replace('\"','').replace('”','')\n",
        "dataset = dataset.split()\n",
        "dataset = ' '.join(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6YM738Nlnuy"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aIi0DHklqs9"
      },
      "outputs": [],
      "source": [
        "pickle.dump(tokenizer,open('token.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DccWtv27ltNO"
      },
      "outputs": [],
      "source": [
        "words_to_sequence = tokenizer.texts_to_sequences([dataset])[0]\n",
        "vocabulary_sz = len(tokenizer.word_index)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7HRm9kylwV8"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for i in range(3,len(words_to_sequence)):\n",
        "    word = words_to_sequence[i-3:i+1]\n",
        "    sequences.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28I8O9cElzyj"
      },
      "outputs": [],
      "source": [
        "sequences = np.array(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUkNyjsfl2X6"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "for i in sequences:\n",
        "    X.append(i[0:3])\n",
        "    y.append(i[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DaubHvnl5uh"
      },
      "outputs": [],
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXnE2Hz-l9fz"
      },
      "outputs": [],
      "source": [
        "y = to_categorical(y,num_classes=vocabulary_sz)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvI30fDjmACr"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_sz,10,input_length=3))\n",
        "model.add(LSTM(1000,return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000,activation='relu'))\n",
        "model.add(Dense(vocabulary_sz,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQBHB_bOmMm4",
        "outputId": "f459fd3c-14dc-49d7-cfd9-53bc2759bca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784ms/step - loss: 6.6776\n",
            "Epoch 1: loss improved from inf to 6.34368, saving model to next_word.keras\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1316s\u001b[0m 786ms/step - loss: 6.6774\n",
            "Epoch 2/5\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771ms/step - loss: 5.7986\n",
            "Epoch 2: loss improved from 6.34368 to 5.76004, saving model to next_word.keras\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1322s\u001b[0m 774ms/step - loss: 5.7986\n",
            "Epoch 3/5\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784ms/step - loss: 5.4838\n",
            "Epoch 3: loss improved from 5.76004 to 5.45845, saving model to next_word.keras\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1305s\u001b[0m 788ms/step - loss: 5.4838\n",
            "Epoch 4/5\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - loss: 5.2181\n",
            "Epoch 4: loss improved from 5.45845 to 5.21450, saving model to next_word.keras\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1258s\u001b[0m 760ms/step - loss: 5.2181\n",
            "Epoch 5/5\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752ms/step - loss: 4.9797\n",
            "Epoch 5: loss improved from 5.21450 to 4.99158, saving model to next_word.keras\n",
            "\u001b[1m1655/1655\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1272s\u001b[0m 754ms/step - loss: 4.9797\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ee522666e30>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "checkPoint = ModelCheckpoint('next_word.keras', monitor='loss', verbose=1, save_best_only=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.fit(X, y, epochs=5, batch_size=64, callbacks=[checkPoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhn_XOUsnHJm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f8d61871-554b-4345-d35a-7f9e936b9172"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" with open('next_word_model.pkl', 'wb') as file:\\n    pickle.dump(model, file)\\n\\ntokenizer = pickle.load(open('token.pkl', 'rb'))\\nwith open('next_word_model.pkl', 'rb') as file:\\n    loaded_model = pickle.load(file) \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('next_word.keras')\n",
        "''' with open('next_word_model.pkl', 'wb') as file:\n",
        "    pickle.dump(model, file)\n",
        "\n",
        "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
        "with open('next_word_model.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63LhKdlnnpKk"
      },
      "outputs": [],
      "source": [
        "def predict_word(model,tokenizer,text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    sequence = np.array(sequence)\n",
        "    preds = np.argmax(model.predict(sequence))\n",
        "    predicted_word = \"\"\n",
        "    for key, value in tokenizer.word_index.items():\n",
        "        if value == preds:\n",
        "            predicted_word = key\n",
        "            break\n",
        "    return predicted_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJDMHdBwnXPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "4b0fb4ad-d4fe-4d87-dbdc-03727aa56c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'man'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "text = ''\n",
        "predict_word(model,tokenizer,text)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}